{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"04.NLP_Week4_Exercise_Shakespeare_Answer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO","colab_type":"code","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BOwsuGQQY9OL","colab":{}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils as ku \n","import numpy as np "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PRnDnCW-Z7qv","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1597221837198,"user_tz":-330,"elapsed":4964,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"17697dcc-2cab-4de0-8dec-a975d5c48413"},"source":["tokenizer = Tokenizer()\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n","    -O /tmp/sonnets.txt\n","data = open('/tmp/sonnets.txt').read()\n","\n","corpus = data.lower().split(\"\\n\")\n","\n","\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","# create input sequences using list of tokens\n","input_sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tinput_sequences.append(n_gram_sequence)\n","\n","\n","# pad sequences \n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# create predictors and label\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","label = ku.to_categorical(label, num_classes=total_words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-08-12 08:43:53--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.133.128, 74.125.140.128, 108.177.15.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.133.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93578 (91K) [text/plain]\n","Saving to: ‘/tmp/sonnets.txt’\n","\n","\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n","\n","2020-08-12 08:43:53 (101 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w9vH8Y59ajYL","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"ok","timestamp":1597221888512,"user_tz":-330,"elapsed":7810,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"d579e201-3fa5-46d7-ad67-772a4918ceee"},"source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150, return_sequences = True)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(100))\n","model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 10, 100)           321100    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 10, 300)           301200    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10, 300)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 100)               160400    \n","_________________________________________________________________\n","dense (Dense)                (None, 1605)              162105    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3211)              5156866   \n","=================================================================\n","Total params: 6,101,671\n","Trainable params: 6,101,671\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AIg2f1HBxqof","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597223195916,"user_tz":-330,"elapsed":1300660,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"945b08e5-ef80-4421-d0ba-13b7cb8c7dd6"},"source":[" history = model.fit(predictors, label, epochs=100, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.9097 - accuracy: 0.0224\n","Epoch 2/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.5003 - accuracy: 0.0220\n","Epoch 3/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.4039 - accuracy: 0.0237\n","Epoch 4/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.2792 - accuracy: 0.0308\n","Epoch 5/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.1928 - accuracy: 0.0363\n","Epoch 6/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.1186 - accuracy: 0.0382\n","Epoch 7/100\n","484/484 [==============================] - 13s 27ms/step - loss: 6.0408 - accuracy: 0.0402\n","Epoch 8/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.9523 - accuracy: 0.0437\n","Epoch 9/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.8540 - accuracy: 0.0528\n","Epoch 10/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.7410 - accuracy: 0.0572\n","Epoch 11/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.6309 - accuracy: 0.0642\n","Epoch 12/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.5212 - accuracy: 0.0712\n","Epoch 13/100\n","484/484 [==============================] - 13s 26ms/step - loss: 5.4090 - accuracy: 0.0768\n","Epoch 14/100\n","484/484 [==============================] - 13s 26ms/step - loss: 5.3051 - accuracy: 0.0821\n","Epoch 15/100\n","484/484 [==============================] - 13s 27ms/step - loss: 5.2002 - accuracy: 0.0922\n","Epoch 16/100\n","484/484 [==============================] - 13s 26ms/step - loss: 5.0938 - accuracy: 0.0962\n","Epoch 17/100\n","484/484 [==============================] - 13s 26ms/step - loss: 4.9850 - accuracy: 0.1024\n","Epoch 18/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.8895 - accuracy: 0.1129\n","Epoch 19/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.7863 - accuracy: 0.1217\n","Epoch 20/100\n","484/484 [==============================] - 13s 26ms/step - loss: 4.6801 - accuracy: 0.1306\n","Epoch 21/100\n","484/484 [==============================] - 13s 26ms/step - loss: 4.5816 - accuracy: 0.1405\n","Epoch 22/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.4705 - accuracy: 0.1504\n","Epoch 23/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.3721 - accuracy: 0.1634\n","Epoch 24/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.2612 - accuracy: 0.1774\n","Epoch 25/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.1684 - accuracy: 0.1864\n","Epoch 26/100\n","484/484 [==============================] - 13s 27ms/step - loss: 4.0586 - accuracy: 0.2027\n","Epoch 27/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.9551 - accuracy: 0.2219\n","Epoch 28/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.8574 - accuracy: 0.2334\n","Epoch 29/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.7565 - accuracy: 0.2514\n","Epoch 30/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.6721 - accuracy: 0.2700\n","Epoch 31/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.5773 - accuracy: 0.2893\n","Epoch 32/100\n","484/484 [==============================] - 13s 26ms/step - loss: 3.4926 - accuracy: 0.3105\n","Epoch 33/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.4049 - accuracy: 0.3240\n","Epoch 34/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.3117 - accuracy: 0.3467\n","Epoch 35/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.2373 - accuracy: 0.3607\n","Epoch 36/100\n","484/484 [==============================] - 13s 26ms/step - loss: 3.1616 - accuracy: 0.3785\n","Epoch 37/100\n","484/484 [==============================] - 13s 27ms/step - loss: 3.0812 - accuracy: 0.3970\n","Epoch 38/100\n","484/484 [==============================] - 13s 26ms/step - loss: 3.0059 - accuracy: 0.4155\n","Epoch 39/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.9371 - accuracy: 0.4295\n","Epoch 40/100\n","484/484 [==============================] - 13s 26ms/step - loss: 2.8678 - accuracy: 0.4463\n","Epoch 41/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.8023 - accuracy: 0.4599\n","Epoch 42/100\n","484/484 [==============================] - 13s 26ms/step - loss: 2.7381 - accuracy: 0.4748\n","Epoch 43/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.6768 - accuracy: 0.4899\n","Epoch 44/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.6195 - accuracy: 0.4993\n","Epoch 45/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.5578 - accuracy: 0.5160\n","Epoch 46/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.5069 - accuracy: 0.5237\n","Epoch 47/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.4548 - accuracy: 0.5391\n","Epoch 48/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.4031 - accuracy: 0.5494\n","Epoch 49/100\n","484/484 [==============================] - 13s 26ms/step - loss: 2.3516 - accuracy: 0.5634\n","Epoch 50/100\n","484/484 [==============================] - 13s 26ms/step - loss: 2.3081 - accuracy: 0.5722\n","Epoch 51/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.2641 - accuracy: 0.5835\n","Epoch 52/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.2126 - accuracy: 0.5933\n","Epoch 53/100\n","484/484 [==============================] - 13s 26ms/step - loss: 2.1658 - accuracy: 0.6034\n","Epoch 54/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.1293 - accuracy: 0.6095\n","Epoch 55/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.1089 - accuracy: 0.6125\n","Epoch 56/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.0549 - accuracy: 0.6253\n","Epoch 57/100\n","484/484 [==============================] - 13s 27ms/step - loss: 2.0116 - accuracy: 0.6352\n","Epoch 58/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.9708 - accuracy: 0.6421\n","Epoch 59/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.9329 - accuracy: 0.6551\n","Epoch 60/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.9069 - accuracy: 0.6576\n","Epoch 61/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.8799 - accuracy: 0.6663\n","Epoch 62/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.8630 - accuracy: 0.6661\n","Epoch 63/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.8238 - accuracy: 0.6737\n","Epoch 64/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.7863 - accuracy: 0.6832\n","Epoch 65/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.7637 - accuracy: 0.6884\n","Epoch 66/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.7491 - accuracy: 0.6883\n","Epoch 67/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.6985 - accuracy: 0.7021\n","Epoch 68/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.6792 - accuracy: 0.7053\n","Epoch 69/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.6714 - accuracy: 0.7028\n","Epoch 70/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.6325 - accuracy: 0.7122\n","Epoch 71/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.6139 - accuracy: 0.7180\n","Epoch 72/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.5803 - accuracy: 0.7242\n","Epoch 73/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.5753 - accuracy: 0.7245\n","Epoch 74/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.5536 - accuracy: 0.7278\n","Epoch 75/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.5250 - accuracy: 0.7335\n","Epoch 76/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.5024 - accuracy: 0.7418\n","Epoch 77/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.4835 - accuracy: 0.7430\n","Epoch 78/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.4729 - accuracy: 0.7464\n","Epoch 79/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.4658 - accuracy: 0.7436\n","Epoch 80/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.4393 - accuracy: 0.7527\n","Epoch 81/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.4160 - accuracy: 0.7571\n","Epoch 82/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3939 - accuracy: 0.7604\n","Epoch 83/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3814 - accuracy: 0.7616\n","Epoch 84/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3680 - accuracy: 0.7616\n","Epoch 85/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.3576 - accuracy: 0.7696\n","Epoch 86/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3374 - accuracy: 0.7705\n","Epoch 87/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3146 - accuracy: 0.7743\n","Epoch 88/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.3192 - accuracy: 0.7736\n","Epoch 89/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2979 - accuracy: 0.7771\n","Epoch 90/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2798 - accuracy: 0.7795\n","Epoch 91/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.2690 - accuracy: 0.7809\n","Epoch 92/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.2577 - accuracy: 0.7848\n","Epoch 93/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2417 - accuracy: 0.7859\n","Epoch 94/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2401 - accuracy: 0.7857\n","Epoch 95/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2294 - accuracy: 0.7866\n","Epoch 96/100\n","484/484 [==============================] - 13s 26ms/step - loss: 1.2052 - accuracy: 0.7924\n","Epoch 97/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.1975 - accuracy: 0.7924\n","Epoch 98/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.1937 - accuracy: 0.7947\n","Epoch 99/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.1816 - accuracy: 0.7948\n","Epoch 100/100\n","484/484 [==============================] - 13s 27ms/step - loss: 1.1817 - accuracy: 0.7943\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1fXTEO3GJ282","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","loss = history.history['loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training accuracy')\n","plt.title('Training accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.title('Training loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6Vc6PHgxa6Hm","colab":{}},"source":["seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"execution_count":null,"outputs":[]}]}