{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"NLP_C2_W4_lecture_notebook_model_architecture.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"XmZCTX7k2lPt"},"source":["# Word Embeddings: Intro to CBOW model, activation functions and working with Numpy\n","\n","In this lecture notebook you will be given an introduction to the continuous bag-of-words model, its activation functions and some considerations when working with Numpy. \n","\n","Let's dive into it!"]},{"cell_type":"code","metadata":{"id":"Wo42N9Nk2lPu","executionInfo":{"status":"ok","timestamp":1601215056668,"user_tz":-330,"elapsed":1596,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjjHLJ5U2lP1"},"source":["# The continuous bag-of-words model"]},{"cell_type":"markdown","metadata":{"id":"03Cidx_m2lP2"},"source":["The CBOW model is based on a neural network, the architecture of which looks like the figure below, as you'll recall from the lecture.\n","\n","<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='cbow_model_architecture.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:917;height:337;\" /> Figure 1 </div>\n"]},{"cell_type":"markdown","metadata":{"id":"euUbcUmf2lP3"},"source":["## Activation functions"]},{"cell_type":"markdown","metadata":{"id":"ZXtsLyzc2lP3"},"source":["Let's start by implementing the activation functions, ReLU and softmax."]},{"cell_type":"markdown","metadata":{"id":"KyM-pgnD2lP4"},"source":["### ReLU"]},{"cell_type":"markdown","metadata":{"id":"YxY70mXm2lP5"},"source":["ReLU is used to calculate the values of the hidden layer, in the following formulas:\n","\n","\\begin{align}\n"," \\mathbf{z_1} &= \\mathbf{W_1}\\mathbf{x} + \\mathbf{b_1}  \\tag{1} \\\\\n"," \\mathbf{h} &= \\mathrm{ReLU}(\\mathbf{z_1})  \\tag{2} \\\\\n","\\end{align}\n"]},{"cell_type":"markdown","metadata":{"id":"vFccqEd12lP6"},"source":["Let's fix a value for $\\mathbf{z_1}$ as a working example."]},{"cell_type":"code","metadata":{"id":"7ZClEUPx2lP7","executionInfo":{"status":"ok","timestamp":1601215056670,"user_tz":-330,"elapsed":1566,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"70f4067c-5b92-4f03-8bb6-4ffbdf0e3e45","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# Define a random seed so all random outcomes can be reproduced\n","np.random.seed(10)\n","\n","# Define a 5X1 column vector using numpy\n","z_1 = 10*np.random.rand(5, 1)-5\n","\n","# Print the vector\n","z_1"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2.71320643],\n","       [-4.79248051],\n","       [ 1.33648235],\n","       [ 2.48803883],\n","       [-0.01492988]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"NVzNyAN02lQB"},"source":["Notice that using numpy's `random.rand` function returns a numpy array filled with values taken from a uniform distribution over [0, 1). Numpy allows vectorization so each value is multiplied by 10 and then substracted 5."]},{"cell_type":"markdown","metadata":{"id":"X0kvCtLg2lQD"},"source":["To get the ReLU of this vector, you want all the negative values to become zeros.\n","\n","First create a copy of this vector."]},{"cell_type":"code","metadata":{"id":"gY5aH9Ci2lQE","executionInfo":{"status":"ok","timestamp":1601215056672,"user_tz":-330,"elapsed":1558,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}}},"source":["# Create copy of vector and save it in the 'h' variable\n","h = z_1.copy()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGsokxgJ2lQI"},"source":["Now determine which of its values are negative."]},{"cell_type":"code","metadata":{"id":"phowjAwU2lQJ","executionInfo":{"status":"ok","timestamp":1601215056674,"user_tz":-330,"elapsed":1540,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"f911a6d6-7916-417c-de1e-5b25885d3bcc","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# Determine which values met the criteria (this is possible because of vectorization)\n","h < 0"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[False],\n","       [ True],\n","       [False],\n","       [False],\n","       [ True]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"v0Rr-L-D2lQO"},"source":["You can now simply set all of the values which are negative to 0."]},{"cell_type":"code","metadata":{"id":"nlaEDcAV2lQP","executionInfo":{"status":"ok","timestamp":1601215056675,"user_tz":-330,"elapsed":1535,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}}},"source":["# Slice the array or vector. This is the same as applying ReLU to it\n","h[h < 0] = 0"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVtcrB8M2lQT"},"source":["And that's it: you have the ReLU of $\\mathbf{z_1}$!"]},{"cell_type":"code","metadata":{"id":"ssnSitV-2lQU","executionInfo":{"status":"ok","timestamp":1601215056677,"user_tz":-330,"elapsed":1522,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"7bd06b7f-0d63-4e7c-95af-90470d7c8b5b","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# Print the vector after ReLU\n","h"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2.71320643],\n","       [0.        ],\n","       [1.33648235],\n","       [2.48803883],\n","       [0.        ]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6HGNdu8q2lQZ"},"source":["**Now implement ReLU as a function.**"]},{"cell_type":"code","metadata":{"id":"eMYILIBT2lQZ","executionInfo":{"status":"ok","timestamp":1601215056678,"user_tz":-330,"elapsed":1516,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}}},"source":["# Define the 'relu' function that will include the steps previously seen\n","def relu(z):\n","    result = z.copy()\n","    result[result < 0] = 0\n","    return result"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yK9WQW9Q2lQj"},"source":["**And check that it's working.**"]},{"cell_type":"code","metadata":{"id":"joSnRzKT2lQk","executionInfo":{"status":"ok","timestamp":1601215056679,"user_tz":-330,"elapsed":1502,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"87575dc2-9d74-4e34-da18-bd052f47c225","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# Define a new vector and save it in the 'z' variable\n","z = np.array([[-1.25459881], [ 4.50714306], [ 2.31993942], [ 0.98658484], [-3.4398136 ]])\n","\n","# Apply ReLU to it\n","relu(z)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.        ],\n","       [4.50714306],\n","       [2.31993942],\n","       [0.98658484],\n","       [0.        ]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"FgM7SrWk2lQr"},"source":["Expected output:\n","\n","    array([[0.        ],\n","           [4.50714306],\n","           [2.31993942],\n","           [0.98658484],\n","           [0.        ]])"]},{"cell_type":"markdown","metadata":{"id":"boMiJ3h_2lQs"},"source":["### Softmax"]},{"cell_type":"markdown","metadata":{"id":"1EWSDyNQ2lQv"},"source":["The second activation function that you need is softmax. This function is used to calculate the values of the output layer of the neural network, using the following formulas:\n","\n","\\begin{align}\n"," \\mathbf{z_2} &= \\mathbf{W_2}\\mathbf{h} + \\mathbf{b_2}   \\tag{3} \\\\\n"," \\mathbf{\\hat y} &= \\mathrm{softmax}(\\mathbf{z_2})   \\tag{4} \\\\\n","\\end{align}\n","\n","To calculate softmax of a vector $\\mathbf{z}$, the $i$-th component of the resulting vector is given by:\n","\n","$$ \\textrm{softmax}(\\textbf{z})_i = \\frac{e^{z_i} }{\\sum\\limits_{j=1}^{V} e^{z_j} }  \\tag{5} $$\n","\n","Let's work through an example."]},{"cell_type":"code","metadata":{"id":"ErZcnDt82lQw","executionInfo":{"status":"ok","timestamp":1601215056681,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"8a287ff4-14ad-4637-c5e5-4866249cf334","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Define a new vector and save it in the 'z' variable\n","z = np.array([9, 8, 11, 10, 8.5])\n","\n","# Print the vector\n","z"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 9. ,  8. , 11. , 10. ,  8.5])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"UNp99VAB2lQ4"},"source":["You'll need to calculate the exponentials of each element, both for the numerator and for the denominator."]},{"cell_type":"code","metadata":{"id":"zmdqPTlb2lQ4","executionInfo":{"status":"ok","timestamp":1601215056685,"user_tz":-330,"elapsed":1475,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"31e94fb3-f722-425e-e2ab-858a2e5433f9","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Save exponentials of the values in a new vector\n","e_z = np.exp(z)\n","\n","# Print the vector with the exponential values\n","e_z"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 8103.08392758,  2980.95798704, 59874.1417152 , 22026.46579481,\n","        4914.7688403 ])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"gFGKDlkl2lQ9"},"source":["The denominator is equal to the sum of these exponentials."]},{"cell_type":"code","metadata":{"id":"HUWIVKGI2lQ-","executionInfo":{"status":"ok","timestamp":1601215056686,"user_tz":-330,"elapsed":1457,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"08d4fe1e-3aca-4c70-855d-e21ad815e7ac","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Save the sum of the exponentials\n","sum_e_z = np.sum(e_z)\n","\n","# Print sum of exponentials\n","sum_e_z"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["97899.41826492078"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"2Va2dt4d2lRB"},"source":["And the value of the first element of $\\textrm{softmax}(\\textbf{z})$ is given by:"]},{"cell_type":"code","metadata":{"id":"tyfjplkv2lRC","executionInfo":{"status":"ok","timestamp":1601215056687,"user_tz":-330,"elapsed":1437,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"0e96cdd3-347c-4d8a-c6a3-dc5a416eddb1","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Print softmax value of the first element in the original vector\n","e_z[0]/sum_e_z"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.08276947985173956"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"eqMG1JKc2lRH"},"source":["This is for one element. You can use numpy's vectorized operations to calculate the values of all the elements of the $\\textrm{softmax}(\\textbf{z})$ vector in one go.\n","\n","**Implement the softmax function.**"]},{"cell_type":"code","metadata":{"id":"wEn8edMm2lRH","executionInfo":{"status":"ok","timestamp":1601215057178,"user_tz":-330,"elapsed":1922,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}}},"source":["# Define the 'softmax' function that will include the steps previously seen\n","def softmax(z):\n","    e_z = np.exp(z)\n","    sum_e_z = np.sum(e_z)\n","    return e_z / sum_e_z"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5CHL437Z2lRM"},"source":["**Now check that it works.**"]},{"cell_type":"code","metadata":{"id":"0-yS4BrT2lRM","executionInfo":{"status":"ok","timestamp":1601215057180,"user_tz":-330,"elapsed":1908,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"fb25059e-841a-4449-a524-ee054fb30119","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Print softmax values for original vector\n","softmax([9, 8, 11, 10, 8.5])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"jtgie8i22lRQ"},"source":["Expected output:\n","\n","    array([0.08276948, 0.03044919, 0.61158833, 0.22499077, 0.05020223])"]},{"cell_type":"markdown","metadata":{"id":"LCce9w0n2lRR"},"source":["Notice that the sum of all these values is equal to 1."]},{"cell_type":"code","metadata":{"id":"fLVZ4QIB2lRR","executionInfo":{"status":"ok","timestamp":1601215057181,"user_tz":-330,"elapsed":1889,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"f7311b14-ad3e-46a3-da9a-9d9b8bccfbc5","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Assert that the sum of the softmax values is equal to 1\n","np.sum(softmax([9, 8, 11, 10, 8.5])) == 1"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"OyG78DFQ2lRV"},"source":["## Dimensions: 1-D arrays vs 2-D column vectors\n","\n","Before moving on to implement forward propagation, backpropagation, and gradient descent in the next lecture notebook, let's have a look at the dimensions of the vectors you've been handling until now.\n","\n","Create a vector of length $V$ filled with zeros."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4bCde7pv2lRW","executionInfo":{"status":"ok","timestamp":1601215057189,"user_tz":-330,"elapsed":1872,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"be735224-7d4c-4577-a55f-d34cc982dc60","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Define V. Remember this was the size of the vocabulary in the previous lecture notebook\n","V = 5\n","\n","# Define vector of length V filled with zeros\n","x_array = np.zeros(V)\n","\n","# Print vector\n","x_array"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"rHU0E4so2lRa"},"source":["This is a 1-dimensional array, as revealed by the `.shape` property of the array."]},{"cell_type":"code","metadata":{"id":"NTps3VFw2lRb","executionInfo":{"status":"ok","timestamp":1601215057191,"user_tz":-330,"elapsed":1858,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"6cce5e21-10c8-45dd-b8eb-482b6db21a7d","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Print vector's shape\n","x_array.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5,)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"2agvvGIL2lRf"},"source":["To perform matrix multiplication in the next steps, you actually need your column vectors to be represented as a matrix with one column. In numpy, this matrix is represented as a 2-dimensional array.\n","\n","The easiest way to convert a 1D vector to a 2D column matrix is to set its `.shape` property to the number of rows and one column, as shown in the next cell."]},{"cell_type":"code","metadata":{"id":"HOuEglI02lRf","executionInfo":{"status":"ok","timestamp":1601215057192,"user_tz":-330,"elapsed":1841,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"824fbc98-070f-4962-95db-e5ef9762b4d1","colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["# Copy vector\n","x_column_vector = x_array.copy()\n","\n","# Reshape copy of vector\n","x_column_vector.shape = (V, 1)  # alternatively ... = (x_array.shape[0], 1)\n","\n","# Print vector\n","x_column_vector"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"yxHUMqyl2lRj"},"source":["The shape of the resulting \"vector\" is:"]},{"cell_type":"code","metadata":{"id":"cCqNEbGG2lRk","executionInfo":{"status":"ok","timestamp":1601215057193,"user_tz":-330,"elapsed":1824,"user":{"displayName":"Uday Pratap Yati","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj471mFfPb74fTJaY831rOrH32GTTiGtD-sz0gmNw=s64","userId":"07167909339760484251"}},"outputId":"bd3ad0fe-fa80-4a3a-cf86-30ad201b930f","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Print vector's shape\n","x_column_vector.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 1)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"eWmkaBYX2lRo"},"source":["So you now have a 5x1 matrix that you can use to perform standard matrix multiplication."]},{"cell_type":"markdown","metadata":{"id":"g7OtJFDd2lRp"},"source":["**Congratulations on finishing this lecture notebook!** Hopefully you now have a better understanding of the activation functions used in the continuous bag-of-words model, as well as a clearer idea of how to leverage Numpy's power for these types of mathematical computations.\n","\n","In the next lecture notebook you will get a comprehensive dive into:\n","\n","- Forward propagation.\n","\n","- Cross-entropy loss.\n","\n","- Backpropagation.\n","\n","- Gradient descent.\n","\n","**See you next time!**"]}]}