## Natural Language Processing with Sequence Models
- Train a neural network with GLoVe word embeddings to perform sentiment analysis of tweets.
- Generate synthetic Shakespeare text using a Gated Recurrent Unit (GRU) language model.
- Train a recurrent neural network to perform named entity recognition (NER) using LSTMs with linear layers.
- Use so-called ‘Siamese’ LSTM models to compare questions in a corpus and identify those that are worded differently but have the same meaning.

### Week 1
Build a sophisticated tweet classifier that places tweets into positive or negative sentiment categories, using a deep neural network.
- Feature extraction
- Supervised machine learning
- Binary classification
- Text preprocessing
- ReLU
- Python classes
- Trax
- Neural networks
